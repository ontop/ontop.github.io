(window.webpackJsonp=window.webpackJsonp||[]).push([[19],{396:function(t,a,s){"use strict";s.r(a);var e=s(51),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"support-a-new-database-system"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#support-a-new-database-system"}},[t._v("#")]),t._v(" Support a new database system")]),t._v(" "),s("p",[t._v("This page describes how Ontop can be extended to support a novel relational database system (RDBMS).")]),t._v(" "),s("p",[t._v("The following RDBMSs are currently supported:")]),t._v(" "),s("ul",[s("li",[t._v("DB2")]),t._v(" "),s("li",[t._v("MySQL / MariaDB")]),t._v(" "),s("li",[t._v("Oracle")]),t._v(" "),s("li",[t._v("PostgreSQL")]),t._v(" "),s("li",[t._v("SQL server")]),t._v(" "),s("li",[t._v("H2")]),t._v(" "),s("li",[t._v("Denodo")]),t._v(" "),s("li",[t._v("Dremio")]),t._v(" "),s("li",[t._v("Apache Spark SQL & Databricks")]),t._v(" "),s("li",[t._v("Teiid")]),t._v(" "),s("li",[t._v("Snowflake")]),t._v(" "),s("li",[t._v("Trino")]),t._v(" "),s("li",[t._v("Presto")]),t._v(" "),s("li",[t._v("Athena")]),t._v(" "),s("li",[t._v("Redshift")]),t._v(" "),s("li",[t._v("DuckDB")])]),t._v(" "),s("p",[t._v("It is relatively easy though to extend Ontop's source code in order to support an additional RDBMS, thanks to dependency injection.")]),t._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[t._v("New: Guided Implementation")]),t._v(" "),s("p",[t._v("Ontop also provides a "),s("a",{attrs:{href:"https://github.com/ontop/dialect-factory-scaffolding",target:"_blank",rel:"noopener"}},[t._v("python tool"),s("OutboundLink")],1),t._v(" that automatically generates a large part of the required code end simplifies the process of developing support for new SQL dialects.")]),t._v(" "),s("p",[t._v("Using it minimizes the overhead for the implementation of new dialect support and allows you to test your code easily right away.")])]),t._v(" "),s("p",[s("em",[t._v("This page provides a detailed explanation of the key concepts that need to be implemented, and was updated with Ontop 5.0.2. For newer versions of Ontop, it may no longer be up-to-date.")])]),t._v(" "),s("h2",{attrs:{id:"required-implementations"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#required-implementations"}},[t._v("#")]),t._v(" Required implementations")]),t._v(" "),s("p",[t._v("Two implementations must be provided, each for a different interface that already has a default (abstract) implementation.")]),t._v(" "),s("p",[t._v("These implementations dictate what the datatypes of the RDBMS are and how certain function symbols can be translated into the SQL dialect supported by the RDBMS.")]),t._v(" "),s("p",[t._v("The default implementation of each of these interfaces is often sufficient to handle many query operators and functions.  As a result, only a few methods generally need to be overwritten,\nto account for specificities of the new SQL dialect.")]),t._v(" "),s("p",[t._v("The 2 required implementations are the DB function symbol factory and the DB datatype factory.")]),t._v(" "),s("h3",{attrs:{id:"db-function-symbol-factory"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#db-function-symbol-factory"}},[t._v("#")]),t._v(" DB function symbol factory")]),t._v(" "),s("p",[t._v("The "),s("em",[t._v("DB function symbol factory")]),t._v(" provides function symbols\nwhich can be directly serialized into the target SQL dialect (e.g. "),s("code",[t._v("LENGTH")]),t._v(" or "),s("code",[t._v("CURRENT_TIMESTAMP")]),t._v("). This factory has methods for common operations with precise semantics (e.g. concatenating 3 string arguments in a null-rejecting manner).")]),t._v(" "),s("p",[t._v("The interface to implement is "),s("code",[t._v("DBFunctionSymbolFactory")]),t._v("."),s("br"),t._v("\nAnd the default implementation is "),s("code",[t._v("AbstractSQLDBFunctionSymbolFactory")]),t._v(".")]),t._v(" "),s("p",[t._v("For instance, the DB function symbol factory for PostgreSQL within Ontop is the class "),s("code",[t._v("PostgreSQLDBFunctionSymbolFactory")]),t._v(".")]),t._v(" "),s("div",{staticClass:"custom-block warning"},[s("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),s("p",[t._v("This interface should not be confused with the "),s("code",[t._v("FunctionSymbolFactory")]),t._v(", which is in charge of constructing\nSPARQL function symbols and other function symbols that cannot be directly serialized into SQL.")])]),t._v(" "),s("p",[t._v("A basic template for this implementation is provided here:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("NewDialectDBFunctionSymbolFactory")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("AbstractSQLDBFunctionSymbolFactory")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Inject")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DuckDBDBFunctionSymbolFactory")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TypeFactory")]),t._v(" typeFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("super")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createNewDialectRegularFunctionTable")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("typeFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" typeFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTable")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBFunctionSymbol")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createNewDialectRegularFunctionTable")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TypeFactory")]),t._v(" typeFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBTypeFactory")]),t._v(" dbTypeFactory "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" typeFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getDBTypeFactory")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBTermType")]),t._v(" abstractRootDBType "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dbTypeFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getAbstractRootDBType")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Table")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBFunctionSymbol")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" table "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashBasedTable")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("create")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createDefaultRegularFunctionTable")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("typeFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n            ------------------------------------------\n            -       Changed Function Symbols         -\n            ------------------------------------------\n        */")]),t._v("\n\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTable")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("copyOf")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("table"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n        ------------------------------------------\n        -             Implementations            -\n        ------------------------------------------\n    */")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("In the template above, two code blocks are commented out. We will now look at each of them individually.")]),t._v(" "),s("h4",{attrs:{id:"changed-function-symbols"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#changed-function-symbols"}},[t._v("#")]),t._v(" "),s("strong",[t._v("Changed Function Symbols")])]),t._v(" "),s("p",[t._v("The "),s("em",[t._v("regular function table")]),t._v(" is a dictionary, that maps from function names to the function symbol instance it corresponds to. The abstract base classes we inherit from already define a default function symbol table that includes all commonly used SQL functions. In some cases, however, some of these default function symbols need to be changed. For these cases, new entries can be created in this block, to override existing, bad entries.")]),t._v(" "),s("p",[t._v("A popular example is the "),s("code",[t._v("CURRENT_TIMESTAMP")]),t._v(" function symbol. By default, it is created as a simple function with arity 0 of the form "),s("code",[t._v("CURRENT_TIMESTAMP()")]),t._v(". In some dialects, however, the current time is called without parentheses, simply in the form "),s("code",[t._v("CURRENT_TIMESTAMP")]),t._v(". In this case, we need to override the function symbol created by the default implementation, to not include parentheses:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBFunctionSymbol")]),t._v(" nowFunctionSymbol "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("WithoutParenthesesSimpleTypedDBFunctionSymbolImpl")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    CURRENT_TIMESTAMP_STR"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dbTypeFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getDBDateTimestampType")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" abstractRootDBType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\ntable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("CURRENT_TIMESTAMP_STR"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nowFunctionSymbol"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("The "),s("code",[t._v("CURRENT_TIMESTAMP")]),t._v(" function is now a "),s("code",[t._v("WithoutParenthesesSimpleTypedDBFunctionSymbol")]),t._v(", so when generating SQL queries, ontop will not include the parentheses. By putting this new function symbol into the table at the key "),s("code",[t._v("CURRENT_TIMESTAMP_STR")]),t._v(", we override the default behaviour that was put into the table by the default method.")]),t._v(" "),s("h4",{attrs:{id:"implementations"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#implementations"}},[t._v("#")]),t._v(" "),s("strong",[t._v("Implementations")])]),t._v(" "),s("p",[t._v("A set of serialization methods have been left abstract by the base classes. These "),s("em",[t._v("always")]),t._v(" have to be implemented for each new dialect.")]),t._v(" "),s("p",[t._v("All such methods share the same structure:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" serialize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("FUNCTION_NAME"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableList")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Function")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TermFactory")]),t._v(" termFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("Here, "),s("code",[t._v("terms")]),t._v(" is the list of arguments that were passed to the function, "),s("code",[t._v("termConverter")]),t._v(" ist a function that can be used to transform any given term into its SQL equivalent, and termFactory can be used to generate new terms that may be required for some functions.")]),t._v(" "),s("p",[t._v("We will now go through each of them and provide example implementations.")]),t._v(" "),s("p",[s("em",[s("strong",[t._v("Contains")])]),t._v(":")]),t._v(" "),s("p",[t._v("This function returns a boolean value, indicating whether a given string (argument 2) is included in a different string (argument 1). While some dialects have their own "),s("code",[t._v("CONTAINS")]),t._v(" functions, for others it may have to be implemented through a string search, like in this example:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("serializeContains")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableList")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Function")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TermFactory")]),t._v(" termFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"(POSITION(%s IN %s) > 0)"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                            termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                            termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[s("em",[s("strong",[t._v("StrBefore")])]),t._v(":")]),t._v(" "),s("p",[t._v("This function returns the section of a given string (argument 1) before the first appearance of a given search string (argument 2). If the searched string is not contained in the base string, an empty string is returned instead. In many languages, this can be implemented using string search and substring methods.")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("serializeStrBefore")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableList")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Function")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TermFactory")]),t._v(" termFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" str "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" before "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SUBSTRING(%s,1,POSITION(%s IN %s)-1)"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" before"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[s("em",[s("strong",[t._v("StrAfter")])]),t._v(":")]),t._v(" "),s("p",[t._v("The opposite of "),s("code",[t._v("STRBEFORE")]),t._v(", this function returns the section of a given string (argument 1) "),s("em",[t._v("after")]),t._v(" the first appearance of a search string (argument 2). This function can be implemented similarly:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("serializeStrBefore")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableList")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Function")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TermFactory")]),t._v(" termFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" str "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" before "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SUBSTRING(%s, IF(POSITION(%s IN %s) != 0, POSITION(%s IN %s) + LENGTH(%s), 0))"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" after"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" after"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" after"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[s("em",[s("strong",[t._v("Tz")])]),t._v(":\nThis function extracts the timezone part of a given timestamp. An example implementation may look like this:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("serializeTz")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableList")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Function")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TermFactory")]),t._v(" termFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" str "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"(LPAD(EXTRACT(TIMEZONE_HOUR FROM %s)::text,2,'0') || ':' || LPAD(EXTRACT(TIMEZONE_MINUTE FROM %s)::text,2,'0'))\"")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[s("em",[s("strong",[t._v("DateTimeNorm")])]),t._v(":\nThis function converts a given timestamp to the standardized "),s("code",[t._v("ISO 8601")]),t._v(" format. An example implementation may look like this:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("serializeDateTimeNorm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableList")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Function")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TermFactory")]),t._v(" termFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"TO_ISO8601(%s)"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[s("em",[s("strong",[t._v("Hashing Functions")])]),t._v(":")]),t._v(" "),s("p",[t._v("Ontop supports a set of hasing functions:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("MD5")])]),t._v(" "),s("li",[s("code",[t._v("SHA1")])]),t._v(" "),s("li",[s("code",[t._v("SHA256")])]),t._v(" "),s("li",[s("code",[t._v("SHA384")])]),t._v(" "),s("li",[s("code",[t._v("SHA512")])])]),t._v(" "),s("p",[t._v("For each of them, the implementation of a serialization method is required. An example implementation of the "),s("code",[t._v("MD5")]),t._v(" function may look like this:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("serializeMD5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableList")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Function")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableTerm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TermFactory")]),t._v(" termFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"MD5(%s)"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" termConverter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("terms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p"),t._v(" "),s("p",[t._v("Other than the serialization methods, four additional methods must be implemented by the subclass:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getUUIDNameInDialect")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"[UUID_FUNCTION_NAME]"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("returns the string that represents the name of the UUID in the SQL dialect.")]),t._v(" "),s("p",[t._v("The methods "),s("code",[t._v("createNullRejectingDBConcat(int arity)")]),t._v(", "),s("code",[t._v("createDBConcatOperator(int arity)")]),t._v(", and "),s("code",[t._v("createRegularDBConcat(int arity)")]),t._v(" need to be implemented to define the concat function symbols. The "),s("code",[t._v("DBConcat")]),t._v(" methods define function symbols that represent "),s("code",[t._v("CONCAT")]),t._v(" function calls of a given arity. Sample implementations for them may look like this:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBConcatFunctionSymbol")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createRegularDBConcat")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" arity"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("NullToleratingDBConcatFunctionSymbol")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"CONCAT"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" arity"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dbStringType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" abstractRootDBType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBConcatFunctionSymbol")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createNullRejectingDBConcat")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" arity"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("NullRejectingDBConcatFunctionSymbol")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"CONCAT_NO_NULL"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" arity"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dbStringType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" abstractRootDBType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("The "),s("code",[t._v("createDBConcatOperator(int arity)")]),t._v(" method represents a concat operation executed through a concat operator (often "),s("code",[t._v("+")]),t._v(" or "),s("code",[t._v("||")]),t._v("). It may be implemented like this:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBConcatFunctionSymbol")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createDBConcatOperator")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" arity"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("NullRejectingDBConcatFunctionSymbol")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"||"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" arity"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dbStringType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" abstractRootDBType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Serializers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getOperatorSerializer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"||"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("h3",{attrs:{id:"db-datatype-factory"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#db-datatype-factory"}},[t._v("#")]),t._v(" DB Datatype factory")]),t._v(" "),s("p",[t._v("The "),s("em",[t._v("DB datatype factory")]),t._v(" declares the hierarchy of DB datatypes used by the DBMS, and specifies their correspondence with datatypes used in the RDF graphs (such as xsd datatypes).")]),t._v(" "),s("p",[t._v("The interface to implement (for SQL dialects) is "),s("code",[t._v("SQLDBTypeFactory")]),t._v("."),s("br"),t._v("\nAnd the default implementation is "),s("code",[t._v("DefaultSQLDBTypeFactory")]),t._v(" .")]),t._v(" "),s("p",[t._v("For instance, the datatype factory for PostgreSQL within Ontop is the class "),s("code",[t._v("PostgreSQLDBTypeFactory")]),t._v(".")]),t._v(" "),s("p",[t._v("A basic template for this implementation is provided here:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("NewDialectDBTypeFactory")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultSQLDBTypeFactory")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n        ------------------------------------------\n        -             Type Definitions           -\n        ------------------------------------------\n    */")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@AssistedInject")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("NewDialectDBTypeFactory")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Assisted")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TermType")]),t._v(" rootTermType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Assisted")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TypeFactory")]),t._v(" typeFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("super")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createNewDialectTypeMap")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rootTermType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" typeFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createNewDialectCodeMap")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Map")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBTermType")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createNewDialectTypeMap")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TermType")]),t._v(" rootTermType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TypeFactory")]),t._v(" typeFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n            ------------------------------------------\n            -                Type Map                -\n            ------------------------------------------\n        */")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableMap")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultTypeCode")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createNewDialectCodeMap")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n            ------------------------------------------\n            -               Code Map                -\n            ------------------------------------------\n        */")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n        ------------------------------------------\n        -             Support Flags              -\n        ------------------------------------------\n    */")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("In the template above, four code blocks are commented out. We will now look at each of them individually.")]),t._v(" "),s("h4",{attrs:{id:"type-definitions"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#type-definitions"}},[t._v("#")]),t._v(" "),s("strong",[t._v("Type Definitions")])]),t._v(" "),s("p",[t._v("In this section, we define a set of "),s("code",[t._v("String")]),t._v(" constants that represent the names of datatypes in our SQL dialect. These constants are then used in other code blocks. An excerpt of the "),s("em",[t._v("type definitions")]),t._v(" part in an implementation may look like this:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" BIT_STR "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"BIT"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" INT2_STR "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"INT2"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" INT4_STR "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"INT4"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" INT8_STR "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"INT8"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" FLOAT4_STR "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"FLOAT4"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" FLOAT8_STR "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"FLOAT8"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("h4",{attrs:{id:"type-map"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#type-map"}},[t._v("#")]),t._v(" "),s("strong",[t._v("TYPE MAP")])]),t._v(" "),s("p",[t._v("In this method, we define the contents of the type map for our dialect. We create "),s("code",[t._v("DBTermType")]),t._v(" instances for each supported type and store them in a "),s("code",[t._v("Map")]),t._v(" object, that matches their identifiers to the "),s("code",[t._v("DBTermType")]),t._v(". The base class we extend from already generates an extensive type map for many popular types, such as "),s("code",[t._v("VARCHAR")]),t._v(", "),s("code",[t._v("INTEGER")]),t._v(", "),s("code",[t._v("REAL")]),t._v(", "),s("code",[t._v("DOUBLE")]),t._v(", and more in the method "),s("code",[t._v("createDefaultSQLTypeMap(...)")]),t._v(".  New types can be added to the map in the subclass, and, alternatively, we can override existing entries in the map here. An example implementation of this method may look like this:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Map")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBTermType")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createNewDialectTypeMap")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TermType")]),t._v(" rootTermType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TypeFactory")]),t._v(" typeFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TermTypeAncestry")]),t._v(" rootAncestry "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rootTermType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getAncestry")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Map")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBTermType")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" map "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createDefaultSQLTypeMap")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rootTermType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" typeFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" map"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("h4",{attrs:{id:"code-map"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#code-map"}},[t._v("#")]),t._v(" "),s("strong",[t._v("CODE MAP")])]),t._v(" "),s("p",[t._v('The code map is a dictionary, that maps different type codes to their "default type" for the SQL dialect. This includes the following type codes:')]),t._v(" "),s("ul",[s("li",[s("code",[t._v("STRING")])]),t._v(" "),s("li",[s("code",[t._v("HEXBINARY")])]),t._v(" "),s("li",[s("code",[t._v("LARGE_INTEGER")])]),t._v(" "),s("li",[s("code",[t._v("DECIMAL")])]),t._v(" "),s("li",[s("code",[t._v("DOUBLE")])]),t._v(" "),s("li",[s("code",[t._v("BOOLEAN")])]),t._v(" "),s("li",[s("code",[t._v("DATE")])]),t._v(" "),s("li",[s("code",[t._v("TIME")])]),t._v(" "),s("li",[s("code",[t._v("DATETIMESTAMP")])]),t._v(" "),s("li",[s("code",[t._v("GEOMETRY")])]),t._v(" "),s("li",[s("code",[t._v("GEOGRAPHY")])]),t._v(" "),s("li",[s("code",[t._v("ARRAY")])]),t._v(" "),s("li",[s("code",[t._v("JSON")])])]),t._v(" "),s("p",[t._v("The default implementation already maps many of these to the name of the corresponding data type. To support additional ones, or to override existing mappings, this method can be implemented. An example implementation may look like this:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableMap")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultTypeCode")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createNewDialectCodeMap")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Map")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultTypeCode")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" map "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createDefaultSQLCodeMap")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    \n    map"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultTypeCode")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("JSON"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" JSONB_STR"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableMap")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("copyOf")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("map"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("h4",{attrs:{id:"support-flags"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#support-flags"}},[t._v("#")]),t._v(" "),s("strong",[t._v("Support Flags")])]),t._v(" "),s("p",[t._v("An instance of "),s("code",[t._v("DBTypeFactory")]),t._v(" supports a set of methods that, when called, return a flag indicating if a certain SQL feature is supported by the dialect. These methods are")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("supportsDBGeometryType()")])]),t._v(" "),s("li",[s("code",[t._v("supportsDBGeographyType()")])]),t._v(" "),s("li",[s("code",[t._v("supportsDBDistanceSphere()")])]),t._v(" "),s("li",[s("code",[t._v("supportsJson()")])]),t._v(" "),s("li",[s("code",[t._v("supportsArrayType()")])])]),t._v(" "),s("p",[t._v("Any of these functions can be overridden by the "),s("code",[t._v("DBTypeFactory")]),t._v(" sub-class to return a boolean constant indicating if the type is supported.")]),t._v(" "),s("h4",{attrs:{id:"other-implementations"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#other-implementations"}},[t._v("#")]),t._v(" "),s("strong",[t._v("Other Implementations")])]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("DBTypeFactory")]),t._v(" base-class supports further methods that can be included in sub-classes for fine-tuning. One popular set of such methods are the "),s("code",[t._v("LexicalValue")]),t._v(" methods. These return a "),s("code",[t._v("String")]),t._v(" constant that represents the lexical value the corresponding literal may assume. For instance, by default, the method "),s("code",[t._v("getDBFalseLexicalValue()")]),t._v(" returns the string "),s("code",[t._v('"FALSE"')]),t._v(", as this is a common representation of the boolean "),s("code",[t._v("false")]),t._v(" value in many SQL dialects. To implement the "),s("code",[t._v("DBTypeFactory")]),t._v(" for a dialect that instead uses the digit "),s("code",[t._v("0")]),t._v(" for "),s("code",[t._v("false")]),t._v(" literals, we could override the method like so:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getDBFalseLexicalValue")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("h2",{attrs:{id:"optional-implementations"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#optional-implementations"}},[t._v("#")]),t._v(" Optional implementations")]),t._v(" "),s("p",[t._v("Additional implementations can be optionally provided in replacement of the default implementation.")]),t._v(" "),s("h3",{attrs:{id:"serializer"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#serializer"}},[t._v("#")]),t._v(" Serializer")]),t._v(" "),s("p",[t._v("The "),s("em",[t._v("serializer")]),t._v(" dictates the general shape (SELECT-FROM-WHERE) of the SQL query.")]),t._v(" "),s("p",[t._v("The interface to implement is "),s("code",[t._v("SelectFromWhereSerializer")]),t._v("."),s("br"),t._v("\nAnd the default implementation is "),s("code",[t._v("DefaultSelectFromWhereSerializer")]),t._v(".")]),t._v(" "),s("p",[t._v("For instance, the serializer for PostgreSQL within Ontop is the class "),s("code",[t._v("PostgresSelectFromWhereSerializer")]),t._v(".")]),t._v(" "),s("h3",{attrs:{id:"normalizer"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#normalizer"}},[t._v("#")]),t._v(" Normalizer")]),t._v(" "),s("p",[t._v("The "),s("em",[t._v("normalizer")]),t._v(" addresses limitations of certain DBMSs (such as a non-canonical evaluation of the ORDER BY clause).")]),t._v(" "),s("p",[t._v("The interface to implement is "),s("code",[t._v("DialectExtraNormalizer")]),t._v("."),s("br"),t._v("\nAnd several implementations are already available, some of which are used by several DBMS.")]),t._v(" "),s("p",[t._v("For instance, the normalizer associated to PostgreSQL within Ontop is "),s("code",[t._v("OnlyInPresenceOfDistinctProjectOrderByTermsNormalizer")]),t._v(".")]),t._v(" "),s("h3",{attrs:{id:"metadata-provider"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#metadata-provider"}},[t._v("#")]),t._v(" Metadata provider")]),t._v(" "),s("p",[t._v("The "),s("em",[t._v("metadata provider")]),t._v(" specifies how schema and integrity constraints (for instance primary keys) are retrieved from the DBMS.")]),t._v(" "),s("p",[t._v("The interface to implement is "),s("code",[t._v("MetadataProvider")]),t._v("."),s("br"),t._v("\nAnd the default implementation is "),s("code",[t._v("DefaultDBMetadataProvider")]),t._v(".")]),t._v(" "),s("p",[t._v("For instance, the metadata provider for PostgreSQL within Ontop is "),s("code",[t._v("PostgreSQLDBMetadataProvider")]),t._v(".")]),t._v(" "),s("h2",{attrs:{id:"declaring-an-implementation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#declaring-an-implementation"}},[t._v("#")]),t._v(" Declaring an implementation")]),t._v(" "),s("p",[t._v("All the implementations mentioned above can be declared in the property file "),s("code",[t._v("sql-default.properties")]),t._v(" (which can be found in the directory "),s("code",[t._v("it/unibz/inf/ontop/injection/")]),t._v(" of the "),s("code",[t._v("ontop-rdb")]),t._v(" module).")]),t._v(" "),s("p",[t._v("A key-value pair must be added for each of these implementations, where the key indicates the type of the implementation (serializer, function symbol factory, etc.), and the value is the implementation.")]),t._v(" "),s("p",[t._v("The naming scheme for the keys is the following."),s("br"),t._v("\nLet "),s("code",[t._v("<driverName>")]),t._v(" be the name of the JDBC driver for the RDBMS (for instance, the JDBC driver for PostgreSQL is "),s("code",[t._v("org.postgresql.Driver")]),t._v("."),s("br"),t._v("\nThen the keys are:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("<driverName>-serializer")]),t._v(" for a serializer")]),t._v(" "),s("li",[s("code",[t._v("<driverName>-symbolFactory")]),t._v(" for a DB function symbol factory")]),t._v(" "),s("li",[s("code",[t._v("<driverName>-typeFactory")]),t._v(" for a DB datatype factory")]),t._v(" "),s("li",[s("code",[t._v("<driverName>-normalizer")]),t._v(" for a normalizer")]),t._v(" "),s("li",[s("code",[t._v("<driverName>-metadataProvider")]),t._v(" for a metadata provider")])]),t._v(" "),s("p",[t._v("For instance, the key-value pairs declared for PostgreSQL are:")]),t._v(" "),s("div",{staticClass:"language-properties extra-class"},[s("pre",{pre:!0,attrs:{class:"language-properties"}},[s("code",[s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("org.postgresql.Driver-serializer")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("it.unibz.inf.ontop.generation.serializer.impl.PostgresSelectFromWhereSerializer")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("org.postgresql.Driver-symbolFactory")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("it.unibz.inf.ontop.model.term.functionsymbol.db.impl.PostgreSQLDBFunctionSymbolFactory")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("org.postgresql.Driver-typeFactory")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("it.unibz.inf.ontop.model.type.impl.PostgreSQLDBTypeFactory")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("org.postgresql.Driver-normalizer")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("it.unibz.inf.ontop.generation.normalization.impl.OnlyInPresenceOfDistinctProjectOrderByTermsNormalizer")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("org.postgresql.Driver-metadataProvider")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("it.unibz.inf.ontop.dbschema.impl.PostgreSQLDBMetadataProvider")]),t._v("\n")])])]),s("p",[t._v("A basic set of key-value pairs may be:")]),t._v(" "),s("div",{staticClass:"language-properties extra-class"},[s("pre",{pre:!0,attrs:{class:"language-properties"}},[s("code",[s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name.of.jdbc.Driver-serializer")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("it.unibz.inf.ontop.generation.serializer.impl.DefaultSelectFromWhereSerializer")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name.of.jdbc.Driver-symbolFactory")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("it.unibz.inf.ontop.model.term.functionsymbol.db.impl.NewDialectDBFunctionSymbolFactory")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name.of.jdbc.Driver-typeFactory")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("it.unibz.inf.ontop.model.type.impl.NewDialectDBTypeFactory")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name.of.jdbc.Driver-normalizer")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("it.unibz.inf.ontop.generation.normalization.impl.OnlyInPresenceOfDistinctProjectOrderByTermsNormalizer")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name.of.jdbc.Driver-metadataProvider")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("it.unibz.inf.ontop.dbschema.impl.DefaultSchemaCatalogDBMetadataProvider")]),t._v("\n")])])]),s("h2",{attrs:{id:"preparing-and-running-the-testcases"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#preparing-and-running-the-testcases"}},[t._v("#")]),t._v(" Preparing and Running the Testcases")]),t._v(" "),s("p",[t._v("Ontop currently uses a set of tests called "),s("code",[t._v("lightweight-tests")]),t._v(" to test all main ontop language support features on minimal databases. A simple way of testing the correctness of newly implemented dialect support is to run the same tests a database that uses the corresponding dialect.")]),t._v(" "),s("p",[t._v("This consists of the following steps:")]),t._v(" "),s("ol",[s("li",[t._v("Set up a database with the required testing conditions")]),t._v(" "),s("li",[t._v("Prepare files that assist the connection to the database")]),t._v(" "),s("li",[t._v("Implement sub-classes of the abstract lightweight test classes and run them")])]),t._v(" "),s("p",[t._v("In the following sections, we will discuss each of these steps.")]),t._v(" "),s("h3",{attrs:{id:"setting-up-the-database"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#setting-up-the-database"}},[t._v("#")]),t._v(" Setting up the Database")]),t._v(" "),s("p",[t._v("The exact procedure of the database preparation depends on the database system. In ontop, we generally use docker images that reproduce the exact same database state for each test run so we can test the different dialects automatically.")]),t._v(" "),s("p",[t._v("Each directory inside "),s("code",[t._v("test/lightweight-tests/lightweight-db-test-images/")]),t._v(" corresponds to one docker image, and many of them contain table definitions in "),s("code",[t._v(".sql")]),t._v(" file. For instance, the "),s("code",[t._v("mysql")]),t._v(" directory contains the exact definitions of the three databases that are used for testing, "),s("code",[t._v("books")]),t._v(", "),s("code",[t._v("dbconstraints")]),t._v(", and "),s("code",[t._v("university")]),t._v(".")]),t._v(" "),s("p",[t._v("To prepare the required testing conditions, you can take these "),s("code",[t._v(".sql")]),t._v(" files and run their queries on your database. Should any of the features not be supported, you will be required to either use alternative equivalent features to reach the same final database state, or disable the corresponding test cases.")]),t._v(" "),s("h3",{attrs:{id:"preparing-connection-files"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#preparing-connection-files"}},[t._v("#")]),t._v(" Preparing Connection Files")]),t._v(" "),s("p",[t._v("The directory "),s("code",[t._v("test/lightweight-tests/src/test/resources/")]),t._v(" contains files that are used for setting up an ontop connection with different databases, including "),s("code",[t._v(".obda")]),t._v(" files for the VKG creation and "),s("code",[t._v(".property")]),t._v(" files for JDBC connections. While the "),s("code",[t._v(".obda")]),t._v(" files can usually be reused for different systems, the "),s("code",[t._v(".property")]),t._v(" files must be included for each database system. The directories "),s("code",[t._v("books")]),t._v(" and "),s("code",[t._v("prof")]),t._v(" inside the test resources contain one sub directory for each dialect, where each sub directory in turn includes one "),s("code",[t._v(".properties")]),t._v(" file for the JDBC connection. The "),s("code",[t._v("dbconstraints")]),t._v(" and "),s("code",[t._v("university")]),t._v(" directories, on the other hand, directly contain "),s("code",[t._v(".property")]),t._v(" files for each dialect.")]),t._v(" "),s("p",[t._v("To run all lightweight tests for a new dialect, the corresponding files and directories have to be creates for its JDBC connection. In particular, the connection files should be created in such a way, that the corresponding database/schema of the test is selected as the default database/schema, as the "),s("code",[t._v(".obda")]),t._v(" files access the tables through relative paths.")]),t._v(" "),s("h3",{attrs:{id:"implementing-the-lightweight-test-classes"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#implementing-the-lightweight-test-classes"}},[t._v("#")]),t._v(" Implementing the Lightweight Test Classes")]),t._v(" "),s("p",[t._v("The directory "),s("code",[t._v("test/lightweight-tests/src/test/java/")]),t._v(" contains the test cases that have to run successfully for each new dialect. They are defined in the four abstract classes "),s("code",[t._v("AbstractBindTestWithFunctions")]),t._v(", "),s("code",[t._v("AbstractConstraintTest")]),t._v(", "),s("code",[t._v("AbstractDistinctInAggregateTest")]),t._v(", and "),s("code",[t._v("AbstractLeftJoinProfTest")]),t._v(".")]),t._v(" "),s("p",[t._v("For each new dialect, a new package has to be created at this location, containing the implementations of sub-classes for each of these abstract base classes.")]),t._v(" "),s("h4",{attrs:{id:"bindtestwithfunctions"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bindtestwithfunctions"}},[t._v("#")]),t._v(" "),s("strong",[s("code",[t._v("BindTestWithFunctions")])])]),t._v(" "),s("p",[t._v("This test class tests all main SQL functions that are supported by ontop. It uses the "),s("code",[t._v("books")]),t._v(" database, as well as directly generated data through the SPARQL "),s("code",[t._v("BIND")]),t._v(" function. An example implementation of this class may look like this:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@NewDialectLightweightTest")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BindWithFunctionsNewDialectTest")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("AbstractBindTestWithFunctions")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" PROPERTIES_FILE "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/books/new-dialect/books-new-dialect.properties"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@BeforeAll")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("before")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IOException")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SQLException")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("initOBDA")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("OBDA_FILE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" OWL_FILE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" PROPERTIES_FILE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@AfterAll")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("after")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SQLException")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("release")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n        ------------------------------------------\n        -            Result Definitions          -\n        ------------------------------------------\n    */")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[t._v("NOTE")]),t._v(" "),s("p",[t._v("Using the "),s("code",[t._v("@NewDialectLightweightTest")]),t._v(" annotation requires the definition of the annotation in the same package, similarly to how it was defined for other dialects.")])]),t._v(" "),s("p",[t._v('The code block "Result Definitions" is commented out in the above example. This code block may contain redefinitions of expected results that are tested in the base class. To do this, override the '),s("code",[t._v("get[TEST-NAME]ExpectedValues()")]),t._v(" method here. An example implementation may look like this:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableList")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getConstantIntegerDivideExpectedResults")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableList")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\"0.500\\"^^xsd:decimal"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("Should any of the functionalities not be supported by the SQL dialect, then the corresponding test case may simply be disabled with an exaplanation as to why it is not supported. An example for that may look like this:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Disabled")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"New Dialect does not support SHA384"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("testHashSHA384")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("super")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("testHashSHA384")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("Some test cases are disabled by default.")]),t._v(" "),s("h4",{attrs:{id:"constraint"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#constraint"}},[t._v("#")]),t._v(" "),s("strong",[s("code",[t._v("Constraint")])])]),t._v(" "),s("p",[t._v("This set of test cases tests for the correct interpretation of integrity constraints in the data. It uses the "),s("code",[t._v("dbconstraints")]),t._v(" database. An example implementation may look like this:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@NewDialectLightweightTest")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ConstraintNewDialectTest")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("AbstractConstraintTest")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" PROPERTIES_FILE "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/dbconstraints/dbconstraints-new-dialect.properties"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ConstraintNewDialectTest")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" method"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("super")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("method"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" PROPERTIES_FILE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("Once again, specific tests may be disabled if they are not supported. For database systems that do not support integrity constraints, this class can be ignored.")]),t._v(" "),s("h4",{attrs:{id:"distinctinaggregate"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#distinctinaggregate"}},[t._v("#")]),t._v(" "),s("strong",[s("code",[t._v("DistinctInAggregate")])])]),t._v(" "),s("p",[t._v("This set of test cases runs queries containing aggregate functions that include the "),s("code",[t._v("DISTINCT")]),t._v(" keyword. It can be implemented analogously to the "),s("code",[t._v("BindWithFunctions")]),t._v(" test class.")]),t._v(" "),s("h4",{attrs:{id:"leftjoinprof"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#leftjoinprof"}},[t._v("#")]),t._v(" "),s("strong",[s("code",[t._v("LeftJoinProf")])])]),t._v(" "),s("p",[t._v("This set of test cases runs on the "),s("code",[t._v("university")]),t._v(" database. It accesses items that have to be taken from the database through "),s("code",[t._v("JOIN")]),t._v("s. Furthermore, it tests the optimization procedures employed by ontop to minimize the required number of joins. Once again, it can be implemented analogously to the "),s("code",[t._v("BindWithFunctions")]),t._v(" test class.")]),t._v(" "),s("p",[t._v("If the database management system does not support integrity constraints, many of these test cases will fail because the optimizations will not be performed.")]),t._v(" "),s("h2",{attrs:{id:"further-implementations-and-troubleshooting"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#further-implementations-and-troubleshooting"}},[t._v("#")]),t._v(" Further Implementations and Troubleshooting")]),t._v(" "),s("p",[t._v("Once the basic features and lightweight test cases have been implemented for a dialect, the tests can be run to determine which features still do not work correctly.")]),t._v(" "),s("p",[t._v("If a test case fails, its corresponding feature is likely not yet supported by the current implementation. In these cases, changes need to be applied to the implemented "),s("code",[t._v("DBTypeFactory")]),t._v(" or "),s("code",[t._v("DBFunctionSymbolFactory")]),t._v(" to solve the issue.")]),t._v(" "),s("p",[t._v("In some situations, however, issues may be caused by problems not related to database types or functions. In these cases, one of the following default implementations may also be extended for the new dialect.")]),t._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[t._v("NOTE")]),t._v(" "),s("p",[t._v("New implementations of these classes have to be linked to the driver through the "),s("code",[t._v("sql-default.properties")]),t._v(" file.")])]),t._v(" "),s("h3",{attrs:{id:"defaultschemacatalogdbmetadataprovider-defaultschemadbmetadataprovider-or-defaultdbmetadataprovider"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#defaultschemacatalogdbmetadataprovider-defaultschemadbmetadataprovider-or-defaultdbmetadataprovider"}},[t._v("#")]),t._v(" "),s("strong",[s("code",[t._v("DefaultSchemaCatalogDBMetadataProvider")])]),t._v(", "),s("strong",[s("code",[t._v("DefaultSchemaDBMetadataProvider")])]),t._v(", or "),s("strong",[s("code",[t._v("DefaultDBMetadataProvider")])])]),t._v(" "),s("p",[t._v("If the "),s("code",[t._v("DBMetadataProvider")]),t._v(" assigned to the dialect is not able to perform its expected actions through its default implementation, it may have to be extended with a new sub-class that is particularly tailored for this dialect.")]),t._v(" "),s("p",[t._v("In that case, its methods may be overridden to change the default behavious. Commong targets include:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("insertIntegrityConstraints(...)")]),t._v(" if the dialect does not support integrity constraints.")]),t._v(" "),s("li",[s("code",[t._v("getRelationId(...)")]),t._v(" to return the ID of a given relation.")])]),t._v(" "),s("p",[t._v("Additionally, the constructor may be implemented to determine the default schema or default catalog names if they cannot be accessed directly throug the JDBC, or a different "),s("code",[t._v("QuotedIDFactory")]),t._v(" instance can be passed to the super-class to force ontop to generate quoted identifiers in a specific way.")]),t._v(" "),s("h3",{attrs:{id:"selectfromwhereserializer"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#selectfromwhereserializer"}},[t._v("#")]),t._v(" "),s("strong",[s("code",[t._v("SelectFromWhereSerializer")])])]),t._v(" "),s("p",[t._v("This class is responsible for the serialization of the SQL query frame. Different SQL dialects have different rules as to how the general shape of an SQL query have to be defined. For instance, some dialects allow users to combine "),s("code",[t._v("LIMIT")]),t._v(" and "),s("code",[t._v("OFFSET")]),t._v(" clauses as "),s("code",[t._v("LIMIT <offset>,<limit>")]),t._v(", while others require the form "),s("code",[t._v("OFFSET <offset> LIMIT <limit>")]),t._v(". The following shows a default implementation of a "),s("code",[t._v("SelectFromWhereSerializer")]),t._v(" to achieve the latter behaviour:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Singleton")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("NewDialectSelectFromWhereSerializer")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultSelectFromWhereSerializer")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implements")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SelectFromWhereSerializer")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Inject")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("NewDialectSelectFromWhereSerializer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TermFactory")]),t._v(" termFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("super")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultSQLTermSerializer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("termFactory"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("QuerySerialization")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("serialize")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SelectFromWhereWithModifiers")]),t._v(" selectFromWhere"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBParameters")]),t._v(" dbParameters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" selectFromWhere"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("acceptVisitor")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultRelationVisitingSerializer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dbParameters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getQuotedIDFactory")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("protected")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("serializeLimitOffset")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("long")]),t._v(" limit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("long")]),t._v(" offset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("boolean")]),t._v(" noSortCondition"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"OFFSET %d LIMIT %d"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" offset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" limit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])])}),[],!1,null,null,null);a.default=n.exports}}]);