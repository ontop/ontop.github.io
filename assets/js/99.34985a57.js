(window.webpackJsonp=window.webpackJsonp||[]).push([[99],{476:function(t,a,e){"use strict";e.r(a);var o=e(51),s=Object(o.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"how-to-materialize-data-into-a-graph-database"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#how-to-materialize-data-into-a-graph-database"}},[t._v("#")]),t._v(" How to materialize data into a graph database")]),t._v(" "),e("p",[t._v("In this section, we present two ways to materialize your Knowledge Graph using Ontop.")]),t._v(" "),e("h2",{attrs:{id:"solutions"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#solutions"}},[t._v("#")]),t._v(" Solutions")]),t._v(" "),e("ol",[e("li",[e("h3",{attrs:{id:"materialize-in-rdf-files-and-load-into-a-triplestore"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#materialize-in-rdf-files-and-load-into-a-triplestore"}},[t._v("#")]),t._v(" Materialize in RDF files and load into a triplestore")])])]),t._v(" "),e("p",[t._v("For the first solution, you will need the following prerequisites:")]),t._v(" "),e("ul",[e("li",[t._v("Access to the tutorial H2 database")]),t._v(" "),e("li",[t._v("The "),e("a",{attrs:{href:"../endpoint/input/university-complete.obda"}},[t._v("mapping file")]),t._v(" "),e("code",[t._v("university-complete.obda")]),t._v(" and the "),e("a",{attrs:{href:"../endpoint/input/university-complete.properties"}},[t._v("properties file")]),t._v(" "),e("code",[t._v("university-complete.properties")])]),t._v(" "),e("li",[e("a",{attrs:{href:"https://ontop-vkg.org/guide/cli.html#setup-ontop-cli",target:"_blank",rel:"noopener"}},[t._v("Ontop CLI"),e("OutboundLink")],1)])]),t._v(" "),e("p",[t._v("Using the CLI command "),e("em",[t._v("ontop-materialize")]),t._v(" ("),e("a",{attrs:{href:"https://ontop-vkg.org/guide/cli#ontop-materialize",target:"_blank",rel:"noopener"}},[t._v("https://ontop-vkg.org/guide/cli#ontop-materialize"),e("OutboundLink")],1),t._v("), you can "),e("RouterLink",{attrs:{to:"/tutorial/glossary/#materialization"}},[t._v("materialize")]),t._v(" your KG into one or multiple files. For simplicity, we keep the default option and only materialize it into one file.")],1),t._v(" "),e("div",{staticClass:"language-bash extra-class"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[t._v("./ontop materialize\n--mapping"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("university-complete.obda "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--properties"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("university-complete.properties "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n-f turtle "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n-o materialized-triples.ttl\n")])])]),e("p",[t._v("After running the command, we have all the content of our KG copied to the file "),e("em",[t._v("materialized-triples.ttl")]),t._v(".")]),t._v(" "),e("p",[t._v("Now we load this file in the triplestore of our choice, in this case, we use "),e("a",{attrs:{href:"https://www.ontotext.com/products/graphdb/download/",target:"_blank",rel:"noopener"}},[t._v("GraphDB"),e("OutboundLink")],1),t._v(". This graph database offers "),e("a",{attrs:{href:"https://graphdb.ontotext.com/documentation/10.2/loading-and-updating-data.html",target:"_blank",rel:"noopener"}},[t._v("several ways to load files"),e("OutboundLink")],1),t._v(". Here, since our file is small, we go for the simplest option and load it directly from the UI.")]),t._v(" "),e("p",[t._v("Once this is done, we can query this KG using GraphDB.")]),t._v(" "),e("ol",{attrs:{start:"2"}},[e("li",[e("h3",{attrs:{id:"deploy-a-vkg-and-fetch-its-content-from-the-graph-database"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#deploy-a-vkg-and-fetch-its-content-from-the-graph-database"}},[t._v("#")]),t._v(" Deploy a VKG and fetch its content from the graph database")])])]),t._v(" "),e("p",[t._v("For the second solution, we make use of the concept of KG virtualization.")]),t._v(" "),e("p",[t._v("We deploy the KG as a virtual KG first and then query it from the graph database. In this way, you can retrieve the triples and store them locally in the graph database.")]),t._v(" "),e("p",[t._v("Triples are directly streamed to the graph database: no intermediate file storage is involved, making this solution more direct than the previous one.")]),t._v(" "),e("p",[t._v("let’s deploy the KG as a virtual KG using the "),e("em",[t._v("ontop-endpoint")]),t._v(" command:")]),t._v(" "),e("div",{staticClass:"language-bash extra-class"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[t._v("./ontop endpoint\n--mapping"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("input/university-complete.obda "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--properties"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("input/university-complete.properties "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n")])])]),e("p",[t._v("Now Ontop is deployed as a "),e("RouterLink",{attrs:{to:"/tutorial/glossary/#sparql_endpoint"}},[t._v("SPARQL endpoint")]),t._v(" available at "),e("a",{attrs:{href:"http://localhost:8080/sparql",target:"_blank",rel:"noopener"}},[t._v("http://localhost:8080/sparql"),e("OutboundLink")],1),t._v(".")],1),t._v(" "),e("p",[t._v("Let’s go now to GraphDB. To fetch and insert all the triples from the VKG exposed by Ontop, we run the following SPARQL INSERT query from GraphDB itself:")]),t._v(" "),e("div",{staticClass:"language-sparql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sparql"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("?s")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("?p")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("?o")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SERVICE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token url"}},[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("http://localhost:8080/sparql"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("?s")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("?p")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("?o")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),e("p",[t._v("This query materializes the same triples as with the first approach.")]),t._v(" "),e("h2",{attrs:{id:"choosing-the-right-approach-for-your-use-case"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#choosing-the-right-approach-for-your-use-case"}},[t._v("#")]),t._v(" Choosing the Right Approach for Your Use Case")]),t._v(" "),e("p",[t._v("1. "),e("strong",[t._v("Small Dataset, Easy Communication:")]),t._v(" If your dataset isn't large and you can easily set up communication between the Ontop SPARQL endpoint and the graph database, go with solution #2. It avoids dealing with files and intermediate storage.")]),t._v(" "),e("p",[t._v("2. "),e("strong",[t._v("Large Dataset, Efficient Loading:")]),t._v(" For very large datasets, choose the most efficient loading solution supported by the triplestore, even if it requires more effort to set up.")]),t._v(" "),e("p",[t._v("3. "),e("strong",[t._v("Materializing Fragments of the KG:")]),t._v(" Solution #2 allows easy materialization of specific fragments of the Knowledge Graph by adapting the SPARQL query. You can have hybrid KGs with some parts stored in the graph database and the rest kept virtual.")]),t._v(" "),e("p",[t._v("4. "),e("strong",[t._v("Advantage of Keeping Data Virtual:")]),t._v(" Keeping data virtual is great for large volumes of sensor data that constantly update. It's better to keep this part virtual while storing rich contextual information in the graph database.")]),t._v(" "),e("h2",{attrs:{id:"ontology-usage"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#ontology-usage"}},[t._v("#")]),t._v(" Ontology Usage")]),t._v(" "),e("p",[t._v("If you're familiar with Ontop, you might have noticed that we didn't use an ontology in this example. Providing an ontology to Ontop can result in a significantly larger KG due to the reasoning capabilities embedded in Ontop. However, GraphDB also has reasoning capabilities, allowing reasoning to be done later in GraphDB, making materialization simpler and faster. If your graph database doesn't support reasoning, Ontop can handle it.")])])}),[],!1,null,null,null);a.default=s.exports}}]);